[
  {
    "objectID": "schedule.html",
    "href": "schedule.html",
    "title": "Schedule",
    "section": "",
    "text": "Tools and and Skills for Reproducible Transport Planning\n\n\nDay 1\n\n09:30-10:00 Introduction\n\nWelcome and introductions (participatory)\nDefinitions and motivations\nCourse structure and objectives\n\n10:00-11:00 Development environments, system commands, and version control\n\nIntroduction to VS Code, RStudio, and Jupyter\nKey features and extensions of VS Code\nThe system shell and basic commands\nIntroduction to Git and GitHub\nThe gh command-line tool\n\n11:00-11:15 Break\n11:15-12:30 Sharing code and data\n\nNavigating GitHub\nYour profile and repositories\nCreating and managing repositories\n\nCloning repositories\nMaking changes and committing\nPushing changes to GitHub\n\nCollaboration with GitHub\n\nBranches and pull requests\nMerging changes\nResolving conflicts\n\n\n12:30-13:30 Lunch\n13:30-15:00 Reproducible papers and documentation with Quarto\n\nIntroduction to Quarto\nMarkdown, LaTeX, and file formats\nCode chunks and settings\nPublishing your work\n\n15:00-15:15 Break\n15:15-17:00 Cross-references and citations with Quarto\n\nCross-references\nCitations\nBibliographies\nTables and figures\n\n\n\n\nDay 2\n\n09:00-10:30 Drafting a reproducible paper\n\nRecap of Day 1\nTopic selection\nIndividual work on paper drafts\n\n10:30-10:45 Break\n10:45-12:00 Generating reproducible publication-quality visualisations\n\nAn introduction to visualisation and web application development for transport planning\nA deep dive into ggplot2\nPractical: creating a visualisation for your paper \n\n12:00-13:00 Lunch\n13:00-14:30 Editing other people’s work\n\nReviewing and commenting on papers\nMaking changes and submitting Pull Requests\nControlled chaos: choose a paper and make some changes!\n\n14:30-14:45 Break\n14:45-16:00 Working on papers\n\nPractical session bringing together elements from the course\n\n16:00-17:00 Presentations and wrap-up\n\n\n\nData Science and Digital Tools for Transport Planning\n\n\nDay 1\n\n09:30-10:00 Introduction\n\nWelcome and introductions (participatory)\nDefinitions and motivations\nCourse structure and objectives\n\n10:00-11:00 Development environments, system commands, and version control\n\nIntroduction to VS Code, RStudio, and Jupyter\nKey features and extensions of VS Code\nThe system shell and basic commands\nIntroduction to Git and GitHub\nThe gh command-line tool\n\n11:00-11:15 Break\n11:15-12:30 Sharing code and data\n\nNavigating GitHub\nYour profile and repositories\nCreating and managing repositories\n\nCloning repositories\nMaking changes and committing\nPushing changes to GitHub\n\nCollaboration with GitHub\n\nBranches and pull requests\nMerging changes\nResolving conflicts\n\n\n12:30-13:30 Lunch\n13:30-15:00 Data visualisation\n\nUnivariate plots\nBivariate plots\nMultivariate plots and facets\nInteractive visualisations\nInteractive maps\n\n15:00-15:15 Break\n15:15-17:00 Transport Planning Challenge 1\n\nIntroduction to challenge datasets\nDeciding on a topic and questions\nPractical: working on the challenge\n\n\n\n\nDay 2\n\n09:00-10:30 Data manipulation\n\nKey verbs: filter, select, mutate, summarise\nJoins: inner, left, right, full\nSpatial data operations\n\nSpatial subsetting\nSpatial joins\nSpatial aggregation\n\n\n10:30-10:45 Break\n10:45-12:00 Web application development\n\nStatic vs dynamic web applications\nPractical introduction to Shiny for R and Python\n(Optional): Front-end development\n\n12:00-13:00 Lunch\n13:00-14:30 Transport Planning Challenge 2\n\nDiscussion of datasets from Challenge 1\nDeciding on a topic and questions\nPractical: working on the challenge\n\n14:30-14:45 Break\n14:45-16:30 Transport Planning Challenge 2: continued\n\nPractical: working on the challenge\n\n16:30-17:00 Presentations and wrap-up",
    "crumbs": [
      "Schedule"
    ]
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Data Science and Digital Tools for Transport Planning",
    "section": "",
    "text": "Planned course on Data Science and Digital Tools for Transport Planning",
    "crumbs": [
      "Home"
    ]
  },
  {
    "objectID": "marking-criteria.html",
    "href": "marking-criteria.html",
    "title": "Marking Criteria",
    "section": "",
    "text": "Marks are awarded in 4 categories, accounting for the following criteria:\n**Data processing: 20%**\n\nThe selection and effective use of input datasets that are large (e.g. covering multiple years), complex (e.g. containing multiple variables) and/or diverse (e.g. input datasets from multiple sources are used and where appropriate combined in the analysis)\nDescribe how the data was collected and implications for data quality, and outline how the input datasets were downloaded (with a reproducible example if possible), with a description that will allow others to understand the structure of the inputs and how to import them\nEvidence of data cleaning techniques (e.g. by re-categorising variables)\nAdding value to datasets with joins (key-based or spatial), creation of new variables (also known as feature engineering) and reshaping data (e.g. from wide to long format)\n\nDistinction (70%+): The report makes use of a complex (with many columns and rows) and/or multiple input datasets, efficiently importing them and adding value by creating new variables, recategorising, changing data formats/types, and/or reshaping the data. Selected datasets are very well suited to the research questions, clearly described, with links to the source and understanding of how the datasets were generated.\nMerit (60-69%): The report makes some use of complex or multiple input datasets. The selection, description of, cleaning or value-added to the input datasets show skill and care applied to the data processing stage but with some weaknesses. Selected datasets are appropriate for the research questions, with some description or links to the data source.\nPass (50-59%): There is some evidence of care and attention put into the selection, description of or cleaning of the input datasets but little value has been added. The report makes little use of complex or multiple input datasets. The datasets are not appropriate for the research questions, the datasets are not clearly described, or there are no links to the source or understanding of how the datasets were generated, but the data processing aspect of the work acceptable.\nFail (0-49%): The report does not make use of appropriate input datasets and contains very little or now evidence of data cleaning, adding value to the datasets or reshaping the data. While there may be some evidence of data processing, it is of poor quality and/or not appropriate for the research questions.\n**Visualization and report: 20%**\n\nCreation of figures that are readable and well-described (e.g. with captions and description)\nHigh quality, attractive or advanced techniques (e.g. multi-layered maps or graphs, facets or other advanced techniques)\nUsing visualisation techniques appropriate to the topic and data and interpreting the results correctly (e.g. mentioning potential confounding factors that could account for observed patterns)\nThe report is well-formatted, accessible (e.g. with legible text size and does not contain excessive code in the submitted report) and clearly communicates the data and analysis visually, with appropriate figure captions, cross-references and a consistent style\n\nDistinction (70%+): The report contains high quality, attractive, advanced and meaningful visualisations that are very well-described and interpreted, showing deep understanding of how visualisation can communicate meaning contained within datasets. The report is very well-formatted, accessible and clearly communicates the data and analysis visually.\nMerit (60-69%): The report contains good visualisations that correctly present the data and highlight key patterns. The report is has appropriate formatting.\nPass (50-59%): The report contains basic visualisations or are not well-described or interpreted correctly or the report is poorly formatted, not accessible or does not clearly communicate the data and analysis visually.\nFail (0-49%): The report is of unacceptable quality (would likely be rejected in a professional setting) and/or has poor quality and/or few visualisations, or the visualisations are inappropriate given the data and research questions.\n**Code quality, efficiency and reproducibility: 20%**\n\nCode quality in the submitted source code, including using consistent style, appropriate packages, and clear comments\nEfficiency, including pre-processing to reduce input datasets (avoiding having to share large datasets in the submission for example) and computationally efficient implementations\nThe report is fully reproducible, including generation of figures. There are links to online resources for others wanting to reproduce the analysis for another area, and links to the input data\n\nDistinction (70%+): The source code underlying the report contains high quality, efficient and reproducible code that is very well-written, using consistent syntax and good style, well-commented and uses appropriate packages. The report is fully reproducible, with links to online resources for others wanting to reproduce the analysis for another area, and links to the input data.\nMerit (60-69%): The code is readable and describes the outputs in the report but lacks quality, either in terms of comments, efficiency or reproducibility.\nPass (50-59%): The source code underlying the report describes the outputs in the report but is not well-commented, not efficient or has very limited levels of reproduicibility, with few links to online resources for others wanting to reproduce the analysis for another area, and few links to the input data.\nFail (0-49%): The report has little to no reproducible, readable or efficient code. A report that includes limited well-described code in the main text or in associated files would be considered at the borderline between a fail and a pass. A report that includes no code would be considered a low fail under this criterion.\n**Understanding the data science process, including choice of topic and impact: 40%**\n\nTopic selection, including originality, availability of datasets related to the topic and relevance to solving transport planning problems\nClear research question\nAppropriate reference to the academic, policy and/or technical literature and use of the literature to inform the research question and methods\nUse of appropriate data science methods and techniques\nDiscussion of the strengths and weaknesses of the analysis and input datasets and/or how limitations could be addressed\nDiscuss further research and/or explain the potential impacts of the work\nThe conclusions are supported by the analysis and results\nThe contents of the report fit together logically and support the aims and/or research questions of the report\n\nDistinction (70%+): The report contains a clear research question, appropriate reference to the academic, policy and/or technical literature, use of appropriate data science methods and techniques, discussion of the strengths and weaknesses of the analysis and input datasets and/or how limitations could be addressed. The report discusses further research and/or explores of the potential impacts of the work. Conclusions are supported by the analysis and results, and the contents of the report fit together logically as a cohehisive whole that has a clear direction set-out by the aims and/or research questions. To get a Distinction there should also be evidence of considering the generalisability of the methods and reflections on how it could be built on by others in other areas.\nMerit (60-69%): There is a clear research question. There is some reference to the academic, policy and/or technical literature. The report has a good structure and the results are supported by the analysis. There is some discussion of the strengths and weaknesses of the analysis and input datasets and/or how limitations could be addressed.\nPass (50-59%): The report contains a valid research question but only limited references to appropriate literature or justification. There is evidence of awareness of the limitations of the results and how they inform conclusions, but these are not fully supported by the analysis. The report has a reasonable structure but does not fit together well in a cohesive whole.\nFail (0-49%): The report does not contain a valid research question, has no references to appropriate literature or justification, does not discuss the limitations of the results or how they inform conclusions, or the report does not have a reasonable structure."
  },
  {
    "objectID": "marking-criteria.html#marks",
    "href": "marking-criteria.html#marks",
    "title": "Marking Criteria",
    "section": "",
    "text": "Marks are awarded in 4 categories, accounting for the following criteria:\n**Data processing: 20%**\n\nThe selection and effective use of input datasets that are large (e.g. covering multiple years), complex (e.g. containing multiple variables) and/or diverse (e.g. input datasets from multiple sources are used and where appropriate combined in the analysis)\nDescribe how the data was collected and implications for data quality, and outline how the input datasets were downloaded (with a reproducible example if possible), with a description that will allow others to understand the structure of the inputs and how to import them\nEvidence of data cleaning techniques (e.g. by re-categorising variables)\nAdding value to datasets with joins (key-based or spatial), creation of new variables (also known as feature engineering) and reshaping data (e.g. from wide to long format)\n\nDistinction (70%+): The report makes use of a complex (with many columns and rows) and/or multiple input datasets, efficiently importing them and adding value by creating new variables, recategorising, changing data formats/types, and/or reshaping the data. Selected datasets are very well suited to the research questions, clearly described, with links to the source and understanding of how the datasets were generated.\nMerit (60-69%): The report makes some use of complex or multiple input datasets. The selection, description of, cleaning or value-added to the input datasets show skill and care applied to the data processing stage but with some weaknesses. Selected datasets are appropriate for the research questions, with some description or links to the data source.\nPass (50-59%): There is some evidence of care and attention put into the selection, description of or cleaning of the input datasets but little value has been added. The report makes little use of complex or multiple input datasets. The datasets are not appropriate for the research questions, the datasets are not clearly described, or there are no links to the source or understanding of how the datasets were generated, but the data processing aspect of the work acceptable.\nFail (0-49%): The report does not make use of appropriate input datasets and contains very little or now evidence of data cleaning, adding value to the datasets or reshaping the data. While there may be some evidence of data processing, it is of poor quality and/or not appropriate for the research questions.\n**Visualization and report: 20%**\n\nCreation of figures that are readable and well-described (e.g. with captions and description)\nHigh quality, attractive or advanced techniques (e.g. multi-layered maps or graphs, facets or other advanced techniques)\nUsing visualisation techniques appropriate to the topic and data and interpreting the results correctly (e.g. mentioning potential confounding factors that could account for observed patterns)\nThe report is well-formatted, accessible (e.g. with legible text size and does not contain excessive code in the submitted report) and clearly communicates the data and analysis visually, with appropriate figure captions, cross-references and a consistent style\n\nDistinction (70%+): The report contains high quality, attractive, advanced and meaningful visualisations that are very well-described and interpreted, showing deep understanding of how visualisation can communicate meaning contained within datasets. The report is very well-formatted, accessible and clearly communicates the data and analysis visually.\nMerit (60-69%): The report contains good visualisations that correctly present the data and highlight key patterns. The report is has appropriate formatting.\nPass (50-59%): The report contains basic visualisations or are not well-described or interpreted correctly or the report is poorly formatted, not accessible or does not clearly communicate the data and analysis visually.\nFail (0-49%): The report is of unacceptable quality (would likely be rejected in a professional setting) and/or has poor quality and/or few visualisations, or the visualisations are inappropriate given the data and research questions.\n**Code quality, efficiency and reproducibility: 20%**\n\nCode quality in the submitted source code, including using consistent style, appropriate packages, and clear comments\nEfficiency, including pre-processing to reduce input datasets (avoiding having to share large datasets in the submission for example) and computationally efficient implementations\nThe report is fully reproducible, including generation of figures. There are links to online resources for others wanting to reproduce the analysis for another area, and links to the input data\n\nDistinction (70%+): The source code underlying the report contains high quality, efficient and reproducible code that is very well-written, using consistent syntax and good style, well-commented and uses appropriate packages. The report is fully reproducible, with links to online resources for others wanting to reproduce the analysis for another area, and links to the input data.\nMerit (60-69%): The code is readable and describes the outputs in the report but lacks quality, either in terms of comments, efficiency or reproducibility.\nPass (50-59%): The source code underlying the report describes the outputs in the report but is not well-commented, not efficient or has very limited levels of reproduicibility, with few links to online resources for others wanting to reproduce the analysis for another area, and few links to the input data.\nFail (0-49%): The report has little to no reproducible, readable or efficient code. A report that includes limited well-described code in the main text or in associated files would be considered at the borderline between a fail and a pass. A report that includes no code would be considered a low fail under this criterion.\n**Understanding the data science process, including choice of topic and impact: 40%**\n\nTopic selection, including originality, availability of datasets related to the topic and relevance to solving transport planning problems\nClear research question\nAppropriate reference to the academic, policy and/or technical literature and use of the literature to inform the research question and methods\nUse of appropriate data science methods and techniques\nDiscussion of the strengths and weaknesses of the analysis and input datasets and/or how limitations could be addressed\nDiscuss further research and/or explain the potential impacts of the work\nThe conclusions are supported by the analysis and results\nThe contents of the report fit together logically and support the aims and/or research questions of the report\n\nDistinction (70%+): The report contains a clear research question, appropriate reference to the academic, policy and/or technical literature, use of appropriate data science methods and techniques, discussion of the strengths and weaknesses of the analysis and input datasets and/or how limitations could be addressed. The report discusses further research and/or explores of the potential impacts of the work. Conclusions are supported by the analysis and results, and the contents of the report fit together logically as a cohehisive whole that has a clear direction set-out by the aims and/or research questions. To get a Distinction there should also be evidence of considering the generalisability of the methods and reflections on how it could be built on by others in other areas.\nMerit (60-69%): There is a clear research question. There is some reference to the academic, policy and/or technical literature. The report has a good structure and the results are supported by the analysis. There is some discussion of the strengths and weaknesses of the analysis and input datasets and/or how limitations could be addressed.\nPass (50-59%): The report contains a valid research question but only limited references to appropriate literature or justification. There is evidence of awareness of the limitations of the results and how they inform conclusions, but these are not fully supported by the analysis. The report has a reasonable structure but does not fit together well in a cohesive whole.\nFail (0-49%): The report does not contain a valid research question, has no references to appropriate literature or justification, does not discuss the limitations of the results or how they inform conclusions, or the report does not have a reasonable structure."
  },
  {
    "objectID": "materials.html",
    "href": "materials.html",
    "title": "Course Materials",
    "section": "",
    "text": "Datasets\nSlides",
    "crumbs": [
      "Materials"
    ]
  }
]